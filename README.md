# EMG Gesture Recognition

## About

EMG Gesture Recognition ÊòØ‰∏ÄÂ•óÂç≥ÊôÇËÇåÈõªÔºàEMGÔºâË®äËôüÊì∑ÂèñËàáÊâãÂã¢Ëæ®Ë≠òÁ≥ªÁµ±ÔºåÈáùÂ∞çÂ§öÈÄöÈÅìÁîüÁâ©Ë®äËôüÊèê‰æõÁ´ØÂà∞Á´ØËôïÁêÜÊµÅÁ®ã„ÄÇÈÅ©ÂêàÁî®ÊñºÁ©øÊà¥Âºè‰∫íÂãï„ÄÅÂæ©ÂÅ•/ÈÅãÂãïÁõ£Ê∏¨ËàáÁîüÁâ©Ë®äËôüÈ©ÖÂãï‰ªãÈù¢ÁöÑÁ†îÁ©∂ËàáÂéüÂûã„ÄÇ

## üìã Quick Summary

> üí™ **EMG Gesture Recognition** ÊòØ‰∏ÄÂ•óÂç≥ÊôÇ 8 ÈÄöÈÅìËÇåÈõªË®äËôüÔºàEMGÔºâÁîüÁâ©ÊÑüÊ∏¨‰ªãÈù¢Á≥ªÁµ±ÔºåÂ∞àÁÇ∫ËÇåËÇâÊ¥ªÂãïÁõ£Ê∏¨ËàáÊâãÂã¢Ëæ®Ë≠òË®≠Ë®à„ÄÇüì° Áõ¥Êé•ÈÄ£Êé• WL-EMG Á°¨È´îË®≠ÂÇôÔºåÊîØÊè¥ USB ËóçÁâôÊé•Êî∂Âô®Ëàá BLE Ëá™ÂãïÂÅµÊ∏¨Ôºå‰ª• 200Hz ÂèñÊ®£ÁéáÂç≥ÊôÇÊì∑Âèñ 24-bit ADC È´òÁ≤æÂ∫¶Ë®äËôü„ÄÇüìä Êèê‰æõÈõôË¶ñÂúñÈ°ØÁ§∫Á≥ªÁµ±‚Äî‚ÄîÂÖ®ÈÄöÈÅìÂêà‰ΩµÊ™¢Ë¶ñËàá 8 ÂÄãÁç®Á´ãÁ§∫Ê≥¢Âô®Ôºà2x4 Á∂≤Ê†ºÔºâÔºåÊê≠ÈÖç Metal/OpenGL GPU Âä†ÈÄüÊ∏≤Êüì„ÄÇ‚úã Êï¥Âêà MediaPipe 21 ÈóúÈçµÈªûÊâãÈÉ®È™®Êû∂ËøΩËπ§ÔºåÊîØÊè¥ 9 Á®ÆÈ†êË®≠ÊâãÂã¢Ëæ®Ë≠òÔºàÊè°Êã≥„ÄÅÂºµÈñã„ÄÅÊçèÂèñ„ÄÅË±éÊãáÊåáÁ≠âÔºâ„ÄÇüé• ÂêåÊ≠•ÈåÑË£Ω EMG Ë®äËôü + ÊîùÂΩ±Ê©üÂΩ±ÂÉè + ÊâãÈÉ®È™®Êû∂Êï∏ÊìöÔºåÂÆåÁæéÊôÇÈñìÂ∞çÈΩä„ÄÇ‚ö° Á∂ìÈÅéËø≠‰ª£ÊïàËÉΩÂÑ™ÂåñÔºåCPU ‰ΩøÁî®ÁéáÈôç‰Ωé 54%„ÄÅË®òÊÜ∂È´îÈôç‰Ωé 83%„ÄÇüß† Êé°Áî® PyQt6„ÄÅPyTorch„ÄÅOpenCV Á≠âÊäÄË°ìÊ£ßÔºåÈÅ©Âêà‰∫∫Ê©ü‰∫íÂãï„ÄÅÁ©øÊà¥ÂºèÈÅãÁÆó„ÄÅÁ•ûÁ∂ì‰ªãÈù¢Á†îÁ©∂È†òÂüüÁöÑÁ†îÁ©∂ËÄÖËàáÂ∑•Á®ãÂ∏´ÔºÅ

**Real-time 8-Channel Biosignal Interface for Muscle Activity Monitoring and Hand Gesture Classification**

---

## üí° Why This Exists

Most biosignal research tools are either locked behind expensive proprietary software or limited to offline batch analysis. This project bridges that gap -- a complete desktop application that connects directly to WL-EMG hardware, visualizes 8 channels of raw electromyography signals in real time, and classifies hand gestures using synchronized camera-based hand tracking. It is purpose-built for researchers and engineers working at the intersection of human-computer interaction, wearable computing, and neural interface design.

## üèóÔ∏è Architecture

```
WL-EMG 8-Channel Hardware (EMG + 6-axis IMU)
        |
        | Serial / BLE @ 921600 baud, 200 Hz
        v
+-----------------------------------------------+
|  Data Acquisition Layer                        |
|  serial_device.py / ble.py --> data_parser.py  |
|       --> Ring Buffers (8ch EMG + IMU)         |
+-----------------------------------------------+
        |
        +---> Real-time 8-Channel Waveform Display (PyQtGraph, Metal-accelerated)
        |         - Combined all-channel view
        |         - 8 independent oscilloscopes (2x4 grid)
        |         - 5-level signal quality indicators
        |
        +---> Motion Recording System
        |         - Synchronized EMG + Camera + MediaPipe hand tracking
        |         - .npz data + .mp4 video with skeleton overlay
        |
        +---> Gesture Recognition Pipeline
                  - MediaPipe 21-point hand skeleton
                  - 9 preset gestures (fist, open, pinch, thumbs up, etc.)
                  - Performance profiling and benchmarking
```

### Key Capabilities

- **Hardware-connected**: Reads 8 channels of muscle signals via USB Bluetooth receiver or BLE with auto-detection
- **200 Hz real-time visualization**: Dual-view system (combined + individual oscilloscopes) with Metal/OpenGL GPU acceleration
- **5-level signal quality system**: Standby > Weak > Good > Strong > Optimal, with adaptive thresholds and hysteresis
- **Synchronized recording**: EMG signals + camera video + MediaPipe hand skeleton, perfectly time-aligned
- **Gesture recognition**: 9 preset hand gestures with MediaPipe 21-keypoint tracking
- **Performance optimized**: CPU reduced 54% and memory reduced 83% through iterative profiling (136.9% down to 62.5% CPU, 4147 MB down to 708 MB)

### Hardware Specifications

| Parameter | Value |
|---|---|
| Sample Rate | 200 Hz |
| EMG Channels | 8 (24-bit ADC) |
| IMU | 6-axis (3-axis gyro + 3-axis accelerometer, 16-bit) |
| Baud Rate | 921,600 |
| Packet Size | 29 bytes/packet |
| Display Refresh | 20 FPS |

## üõ†Ô∏è Tech Stack

| Layer | Technology |
|---|---|
| UI Framework | PyQt6, PyQtGraph |
| Signal Processing | NumPy, SciPy, scikit-learn |
| Computer Vision | OpenCV, MediaPipe (21-point hand tracking) |
| Deep Learning | PyTorch |
| Hardware I/O | pyserial (921600 baud), bleak (BLE) |
| GPU Acceleration | Metal (macOS), OpenGL, PyOpenGL |
| Async Runtime | asyncio, qasync |

## üèÅ Quick Start

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install core dependencies
pip install -r requirements.txt

# Install gesture recognition dependencies (optional)
pip install -r requirements_gesture.txt

# Launch the EMG monitor
python main.py
```

### Hardware Setup

1. Connect the WL-EMG Bluetooth receiver via USB
2. Power on the EMG armband and ensure pairing
3. Select the serial port from the dropdown (macOS: `/dev/cu.usbserial-*`)
4. Click Connect -- system auto-calibrates in ~2.5 seconds

> See the included `WL-EMG.pdf` and `WL-EMG2.pdf` documentation for detailed hardware specifications.

## üìÅ Project Structure

```
emg-gesture-recognition/
  main.py                        # Application entry point (Metal-optimized on macOS)
  emg_monitor/
    config.py                    # Central config (channels, sample rate, buffer)
    serial_device.py             # Serial port device manager (921600 baud)
    ble.py                       # BLE device communication
    data_parser.py               # Raw EMG/IMU packet parsing
    buffers.py                   # Ring buffer for signal data
    device_manager.py            # Unified device abstraction
    simulator.py                 # Signal simulator for hardware-free testing
    motion_recorder.py           # Synchronized EMG + camera recording
    ui/
      main_window.py             # PyQt6 main window with dual-view waveforms
  gesture_recognition_demo/      # MediaPipe gesture classification with profiling
  models/                        # Trained gesture recognition models
  recordings/                    # Saved EMG sessions (.npz + .mp4)
  screenshot/                    # Application screenshots
  performance_profiler.py        # System performance benchmarking
  docs/                          # Development documentation
```

## üìú Version History

| Version | Focus |
|---|---|
| v1.0 | 8-channel monitoring with single combined view |
| v2.0 | Dual-view system (combined + 8 independent oscilloscopes) |
| v2.1 | 5-level signal quality with intuitive color mapping |
| v3.0 | IMU integration (archived -- too complex for core use case) |
| v3.1 | Gesture recognition + synchronized motion recording (current) |

---

**Disclaimer:** This system is intended for research and educational purposes only. Not for medical diagnosis.

Built by [Huang Akai (Kai)](https://github.com/akaihuang) -- Creative Technologist, Founder @ Universal FAW Lab