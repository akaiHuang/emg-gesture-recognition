"""
å‹•ä½œè¨˜éŒ„æ¨¡çµ„ï¼šåŒæ­¥è¨˜éŒ„ EMG è¨Šè™Ÿã€æ”å½±æ©Ÿå½±åƒèˆ‡æ‰‹éƒ¨éª¨æ¶

æ­¤æ¨¡çµ„æä¾› EMG è¨Šè™Ÿèˆ‡è¦–è¦ºè³‡æ–™çš„åŒæ­¥è¨˜éŒ„åŠŸèƒ½ï¼Œç”¨æ–¼å»ºç«‹è¨“ç·´è³‡æ–™é›†ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. MediaPipe æ‰‹éƒ¨é—œéµé»è¿½è¹¤ï¼ˆ21 å€‹é—œéµé»ï¼‰
2. EMG è¨Šè™Ÿèˆ‡å½±åƒæ™‚é–“æˆ³åŒæ­¥
3. è³‡æ–™å„²å­˜ï¼ˆ.npz æ ¼å¼ï¼‰èˆ‡å½±ç‰‡è¼¸å‡ºï¼ˆ.mp4ï¼‰
"""

from __future__ import annotations

import time
import threading
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, TYPE_CHECKING

import cv2
import numpy as np

# å»¶é²è¼‰å…¥ MediaPipeï¼Œé¿å…æ‹–æ…¢å•Ÿå‹•é€Ÿåº¦
# MediaPipe import æœƒè§¸ç™¼ matplotlib å­—é«”æƒæï¼ˆåœ¨ macOS ä¸Šå¾ˆæ…¢ï¼‰
if TYPE_CHECKING:
    import mediapipe as mp

MEDIAPIPE_AVAILABLE = False
_mp_module = None
_mp_loading = False  # æ¨™è¨˜æ˜¯å¦æ­£åœ¨è¼‰å…¥


def _lazy_import_mediapipe():
    """å»¶é²è¼‰å…¥ MediaPipeï¼ˆåªåœ¨éœ€è¦æ™‚è¼‰å…¥ï¼‰
    
    æ­¤å‡½æ•¸æœƒåŒæ­¥è¼‰å…¥ MediaPipeï¼Œå¯èƒ½éœ€è¦ 15+ ç§’ï¼ˆé¦–æ¬¡è¼‰å…¥ï¼‰
    å»ºè­°ä½¿ç”¨ _async_import_mediapipe() åœ¨èƒŒæ™¯è¼‰å…¥
    """
    global MEDIAPIPE_AVAILABLE, _mp_module, _mp_loading
    if _mp_module is None and not _mp_loading:
        _mp_loading = True
        try:
            import mediapipe as mp
            _mp_module = mp
            MEDIAPIPE_AVAILABLE = True
            print("âœ… MediaPipe è¼‰å…¥å®Œæˆ")
        except ImportError:
            print("âš ï¸ MediaPipe æœªå®‰è£ï¼Œæ‰‹éƒ¨è¿½è¹¤åŠŸèƒ½å°‡ä¸å¯ç”¨")
            print("   å®‰è£æŒ‡ä»¤: pip install mediapipe")
            MEDIAPIPE_AVAILABLE = False
        finally:
            _mp_loading = False
    return _mp_module


async def _async_import_mediapipe():
    """åœ¨èƒŒæ™¯éåŒæ­¥è¼‰å…¥ MediaPipe
    
    Returns:
        bool: æ˜¯å¦è¼‰å…¥æˆåŠŸ
    """
    import asyncio
    global MEDIAPIPE_AVAILABLE, _mp_module, _mp_loading
    
    if _mp_module is not None:
        return True  # å·²ç¶“è¼‰å…¥
    
    if _mp_loading:
        # å·²ç¶“åœ¨è¼‰å…¥ä¸­ï¼Œç­‰å¾…å®Œæˆ
        while _mp_loading:
            await asyncio.sleep(0.1)
        return MEDIAPIPE_AVAILABLE
    
    _mp_loading = True
    print("ğŸ”„ é–‹å§‹åœ¨èƒŒæ™¯è¼‰å…¥ MediaPipeï¼ˆé€™å¯èƒ½éœ€è¦ 10-15 ç§’ï¼‰...")
    
    def _load_in_thread():
        """åœ¨åŸ·è¡Œç·’ä¸­è¼‰å…¥ MediaPipe"""
        try:
            import mediapipe as mp
            return mp, True
        except ImportError as e:
            print(f"âŒ MediaPipe è¼‰å…¥å¤±æ•—: {e}")
            return None, False
    
    # åœ¨åŸ·è¡Œç·’æ± ä¸­è¼‰å…¥ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç’°ï¼‰
    loop = asyncio.get_event_loop()
    mp_module, success = await loop.run_in_executor(None, _load_in_thread)
    
    _mp_module = mp_module
    MEDIAPIPE_AVAILABLE = success
    _mp_loading = False
    
    if success:
        print("âœ… MediaPipe èƒŒæ™¯è¼‰å…¥å®Œæˆï¼ç¾åœ¨å¯ä»¥é–‹å§‹éŒ„å½±")
    else:
        print("âš ï¸ MediaPipe æœªå®‰è£ï¼Œæ‰‹éƒ¨è¿½è¹¤åŠŸèƒ½å°‡ä¸å¯ç”¨")
        print("   å®‰è£æŒ‡ä»¤: pip install mediapipe")
    
    return success


def is_mediapipe_ready() -> bool:
    """æª¢æŸ¥ MediaPipe æ˜¯å¦å·²æº–å‚™å¥½ä½¿ç”¨"""
    return MEDIAPIPE_AVAILABLE and _mp_module is not None


def is_mediapipe_loading() -> bool:
    """æª¢æŸ¥ MediaPipe æ˜¯å¦æ­£åœ¨è¼‰å…¥ä¸­"""
    return _mp_loading


@dataclass
class MotionFrame:
    """å–®ä¸€å‹•ä½œå¹€è³‡æ–™
    
    Attributes:
        timestamp: æ™‚é–“æˆ³ï¼ˆç§’ï¼Œç›¸å°æ–¼è¨˜éŒ„é–‹å§‹ï¼‰
        emg_data: 8 é€šé“ EMG è¨Šè™Ÿï¼ˆÎ¼Vï¼‰
        hand_landmarks: 21 å€‹æ‰‹éƒ¨é—œéµé» 3D åº§æ¨™ï¼ˆæ­¸ä¸€åŒ– 0-1ï¼‰ï¼Œè‹¥æœªåµæ¸¬åˆ°å‰‡ç‚º None
        frame_image: æ”å½±æ©Ÿå½±åƒï¼ˆBGR æ ¼å¼ï¼‰ï¼Œè‹¥åœç”¨æ”å½±æ©Ÿå‰‡ç‚º None
    """
    timestamp: float
    emg_data: np.ndarray  # shape: (8,)
    hand_landmarks: Optional[np.ndarray] = None  # shape: (21, 3)
    frame_image: Optional[np.ndarray] = None


@dataclass
class RecordingSession:
    """è¨˜éŒ„æœƒè©±è³‡æ–™
    
    Attributes:
        frames: æ‰€æœ‰è¨˜éŒ„çš„å¹€
        metadata: æœƒè©±å…ƒè³‡æ–™
        start_time: é–‹å§‹æ™‚é–“ï¼ˆUnix timestampï¼‰
        gesture_label: æ‰‹å‹¢æ¨™ç±¤ï¼ˆå¦‚ "fist", "open" ç­‰ï¼‰
    """
    frames: List[MotionFrame] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)
    start_time: float = 0.0
    gesture_label: str = ""


class MotionRecorder:
    """EMG + æ”å½±æ©ŸåŒæ­¥è¨˜éŒ„å™¨
    
    æ­¤é¡è² è²¬åŒæ­¥è¨˜éŒ„ EMG è¨Šè™Ÿã€æ”å½±æ©Ÿå½±åƒèˆ‡æ‰‹éƒ¨éª¨æ¶è¿½è¹¤è³‡æ–™ã€‚
    
    ä½¿ç”¨ç¯„ä¾‹ï¼š
        recorder = MotionRecorder(enable_camera=True)
        recorder.start_recording(gesture_label="fist")
        
        # åœ¨ EMG è³‡æ–™å›èª¿ä¸­
        recorder.add_emg_sample(emg_channels)
        
        recorder.stop_recording("recordings/fist_001.npz")
    """
    
    # è¨˜æ†¶é«”ç®¡ç†ï¼šæœ€å¤šä¿ç•™å¤šå°‘å¹€çš„å®Œæ•´å½±åƒï¼ˆå…¶é¤˜åªä¿ç•™ landmarksï¼‰
    MAX_FULL_IMAGE_FRAMES = 100  # ç´„ 0.5 ç§’çš„å½±åƒï¼ˆ200Hz EMGï¼‰
    
    def __init__(
        self, 
        enable_camera: bool = True,
        camera_id: int = 0,
        min_detection_confidence: float = 0.5,
        min_tracking_confidence: float = 0.5
    ):
        """åˆå§‹åŒ–å‹•ä½œè¨˜éŒ„å™¨
        
        Args:
            enable_camera: æ˜¯å¦å•Ÿç”¨æ”å½±æ©Ÿï¼ˆFalse æ™‚åªè¨˜éŒ„ EMGï¼‰
            camera_id: æ”å½±æ©Ÿ IDï¼ˆé€šå¸¸ 0 æ˜¯å…§å»ºæ”å½±æ©Ÿï¼‰
            min_detection_confidence: MediaPipe åµæ¸¬ä¿¡å¿ƒåº¦é–¾å€¼
            min_tracking_confidence: MediaPipe è¿½è¹¤ä¿¡å¿ƒåº¦é–¾å€¼
        """
        self.enable_camera = enable_camera and is_mediapipe_ready()
        self.recording = False
        self.session: Optional[RecordingSession] = None
        
        # æ”å½±æ©Ÿè¨­ç½®ï¼ˆå»¶é²é–‹å•Ÿï¼Œç›´åˆ°é–‹å§‹éŒ„å½±ï¼‰
        self.camera_id = camera_id
        self.cap: Optional[cv2.VideoCapture] = None
        self.mp_hands = None
        self.hands = None
        self.min_detection_confidence = min_detection_confidence
        self.min_tracking_confidence = min_tracking_confidence
        
        # å¿«å–æœ€æ–°å¹€ä»¥é¿å…é‡è¤‡è®€å–æ”å½±æ©Ÿ
        self._cached_frame: Optional[np.ndarray] = None
        self._cached_landmarks: Optional[np.ndarray] = None
        self._cached_has_hand: bool = False
        self._frame_counter: int = 0
        self._process_every_n_frames: int = 3  # æ¯ 3 å¹€æ‰åšä¸€æ¬¡ MediaPipe è™•ç†ï¼ˆé™ä½ CPUï¼‰
        
        # æ”å½±æ©Ÿç·šç¨‹ï¼ˆèƒŒæ™¯è®€å–ï¼Œé¿å…é˜»å¡ä¸»ç·šç¨‹ï¼‰
        self._camera_thread: Optional[threading.Thread] = None
        self._camera_thread_running = False
        self._camera_lock = threading.Lock()
        
        if not is_mediapipe_ready():
            print("âš ï¸ MediaPipe å°šæœªè¼‰å…¥å®Œæˆï¼Œæ”å½±æ©ŸåŠŸèƒ½å·²åœç”¨")
            self.enable_camera = False
    
    def _init_camera(self) -> bool:
        """é–‹å•Ÿæ”å½±æ©Ÿï¼ˆmacOS ä½¿ç”¨ AVFoundation ç¡¬é«”åŠ é€Ÿï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸé–‹å•Ÿ
        """
        if self.cap is not None and self.cap.isOpened():
            return True  # å·²ç¶“é–‹å•Ÿ
        
        # macOS: ä½¿ç”¨ AVFoundation å¾Œç«¯ä»¥ç²å¾—ç¡¬é«”åŠ é€Ÿ
        import platform
        if platform.system() == 'Darwin':  # macOS
            self.cap = cv2.VideoCapture(self.camera_id, cv2.CAP_AVFOUNDATION)
            print("ğŸ ä½¿ç”¨ AVFoundation (ç¡¬é«”åŠ é€Ÿ)")
        else:
            self.cap = cv2.VideoCapture(self.camera_id)
        
        if not self.cap.isOpened():
            print(f"âš ï¸ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ {self.camera_id}")
            return False
        
        # è¨­ç½®æ›´ä½è§£æåº¦å’Œå¹€ç‡ä»¥æå‡æ•ˆèƒ½ä¸¦é™ä½è¨˜æ†¶é«”ä½¿ç”¨
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)   # å¾ 480 é™è‡³ 320
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # å¾ 360 é™è‡³ 240
        self.cap.set(cv2.CAP_PROP_FPS, 15)            # ç¶­æŒ 15 FPS
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)      # æ¸›å°‘ç·©è¡å€ï¼Œé™ä½å»¶é²
        
        # macOS å„ªåŒ–ï¼šå•Ÿç”¨ç¡¬é«”è§£ç¢¼
        if platform.system() == 'Darwin':
            self.cap.set(cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY)
        
        print(f"âœ… æ”å½±æ©Ÿ {self.camera_id} å·²é–‹å•Ÿ (320x240 @ 15fps)")
        
        # å•Ÿå‹•æ”å½±æ©Ÿæ•æ‰ç·šç¨‹
        self._start_camera_thread()
        
        return True
    
    def _start_camera_thread(self) -> None:
        """å•Ÿå‹•æ”å½±æ©ŸèƒŒæ™¯ç·šç¨‹"""
        if self._camera_thread is not None and self._camera_thread.is_alive():
            return  # å·²ç¶“åœ¨é‹è¡Œ
        
        self._camera_thread_running = True
        self._camera_thread = threading.Thread(
            target=self._camera_capture_loop,
            daemon=True,  # å®ˆè­·ç·šç¨‹ï¼Œä¸»ç¨‹å¼çµæŸæ™‚è‡ªå‹•åœæ­¢
            name="CameraCapture"
        )
        self._camera_thread.start()
    
    def _stop_camera_thread(self) -> None:
        """åœæ­¢æ”å½±æ©ŸèƒŒæ™¯ç·šç¨‹"""
        if self._camera_thread is None:
            return
        
        self._camera_thread_running = False
        if self._camera_thread.is_alive():
            self._camera_thread.join(timeout=2.0)  # ç­‰å¾…æœ€å¤š 2 ç§’
        self._camera_thread = None
    
    def _close_camera(self) -> None:
        """é—œé–‰æ”å½±æ©Ÿï¼Œé‡‹æ”¾è³‡æº"""
        self._stop_camera_thread()  # å…ˆåœæ­¢ç·šç¨‹
        
        if self.cap is not None:
            self.cap.release()
            self.cap = None
            print("âœ… æ”å½±æ©Ÿå·²é—œé–‰")
    
    def _init_mediapipe(self) -> bool:
        """åˆå§‹åŒ– MediaPipe æ‰‹éƒ¨è¿½è¹¤
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        """
        if self.hands is not None:
            return True  # å·²ç¶“åˆå§‹åŒ–
        
        mp = _lazy_import_mediapipe()
        if mp is None:
            return False
        
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,  # åªè¿½è¹¤ä¸€éš»æ‰‹
            model_complexity=0,  # ä½¿ç”¨è¼•é‡ç´šæ¨¡å‹ (0=è¼•é‡, 1=å®Œæ•´)
            min_detection_confidence=self.min_detection_confidence,
            min_tracking_confidence=self.min_tracking_confidence
        )
        print("âœ… MediaPipe æ‰‹éƒ¨è¿½è¹¤å·²åˆå§‹åŒ–ï¼ˆè¼•é‡ç´šæ¨¡å‹ï¼‰")
        return True
    
    def _camera_capture_loop(self) -> None:
        """æ”å½±æ©Ÿæ•æ‰ç·šç¨‹ï¼ˆèƒŒæ™¯é‹è¡Œï¼Œé¿å…é˜»å¡ä¸»ç·šç¨‹ï¼‰"""
        print("ğŸ¬ æ”å½±æ©Ÿç·šç¨‹å·²å•Ÿå‹•")
        
        while self._camera_thread_running:
            if self.cap is None or not self.cap.isOpened():
                time.sleep(0.01)
                continue
            
            ret, frame = self.cap.read()
            if not ret:
                time.sleep(0.01)
                continue
            
            # æ°´å¹³ç¿»è½‰å½±åƒï¼ˆä¿®æ­£é¡åƒå•é¡Œï¼‰
            frame = cv2.flip(frame, 1)
            
            self._frame_counter += 1
            
            # åªåœ¨ç‰¹å®šå¹€æ‰åš MediaPipe è™•ç†
            should_process = (self._frame_counter % self._process_every_n_frames == 0)
            
            with self._camera_lock:
                # é‡‹æ”¾èˆŠå¹€ï¼ˆé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼ï¼‰
                if self._cached_frame is not None:
                    del self._cached_frame
                
                self._cached_frame = frame.copy()
                
                if should_process and self.hands is not None:
                    try:
                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        results = self.hands.process(frame_rgb)
                        
                        # é‡‹æ”¾ RGB å¹€ï¼ˆå·²è™•ç†å®Œç•¢ï¼‰
                        del frame_rgb
                        
                        if results.multi_hand_landmarks:
                            hand = results.multi_hand_landmarks[0]
                            
                            # é‡‹æ”¾èˆŠ landmarks
                            if self._cached_landmarks is not None:
                                del self._cached_landmarks
                            
                            self._cached_landmarks = np.array([
                                [lm.x, lm.y, lm.z] 
                                for lm in hand.landmark
                            ])
                            self._cached_has_hand = True
                        else:
                            self._cached_landmarks = None
                            self._cached_has_hand = False
                    except Exception as e:
                        print(f"âš ï¸ MediaPipe è™•ç†éŒ¯èª¤: {e}")
            
            # é‡‹æ”¾åŸå§‹å¹€ï¼ˆå·²è¤‡è£½åˆ°å¿«å–ï¼‰
            del frame
            
            # æ§åˆ¶å¹€ç‡ï¼ˆç´„ 15fpsï¼‰
            time.sleep(1.0 / 15.0)
        
        print("ğŸ¬ æ”å½±æ©Ÿç·šç¨‹å·²åœæ­¢")
    
    def __del__(self):
        """è§£æ§‹å‡½æ•¸ï¼šç¢ºä¿æ”å½±æ©Ÿè¢«æ­£ç¢ºé—œé–‰"""
        self._stop_camera_thread()
        self._close_camera()
    
    def start_recording(self, gesture_label: str = "") -> bool:
        """é–‹å§‹è¨˜éŒ„
        
        Args:
            gesture_label: æ‰‹å‹¢æ¨™ç±¤ï¼ˆå¦‚ "fist", "open", "pinch"ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸé–‹å§‹è¨˜éŒ„
        """
        if self.recording:
            print("âš ï¸ å·²ç¶“åœ¨è¨˜éŒ„ä¸­")
            return False
        
        # å¦‚æœå•Ÿç”¨æ”å½±æ©Ÿï¼Œå…ˆé–‹å•Ÿæ”å½±æ©Ÿå’Œ MediaPipe
        if self.enable_camera:
            if not self._init_camera():
                print("âš ï¸ æ”å½±æ©Ÿé–‹å•Ÿå¤±æ•—ï¼Œå°‡åªè¨˜éŒ„ EMG è³‡æ–™")
                self.enable_camera = False
            elif not self._init_mediapipe():
                print("âš ï¸ MediaPipe åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡åªè¨˜éŒ„ EMG è³‡æ–™")
                self.enable_camera = False
        
        self.recording = True
        self.session = RecordingSession(
            start_time=time.time(),
            gesture_label=gesture_label
        )
        
        # è¨˜éŒ„å…ƒè³‡æ–™
        self.session.metadata = {
            'gesture_label': gesture_label,
            'sample_rate': 200,  # EMG æ¡æ¨£ç‡
            'camera_enabled': self.enable_camera,
            'camera_fps': 30 if self.enable_camera else 0,
            'start_time': time.strftime("%Y-%m-%d %H:%M:%S"),
        }
        
        print(f"âœ… é–‹å§‹è¨˜éŒ„: {gesture_label if gesture_label else 'æœªæ¨™è¨˜'}")
        return True
    
    def add_emg_sample(self, emg_channels: List[float]) -> bool:
        """æ–°å¢ EMG æ¨£æœ¬ï¼ˆç”±ä¸»ç¨‹å¼çš„è³‡æ–™å›èª¿å‡½æ•¸å‘¼å«ï¼‰
        
        æ­¤å‡½æ•¸ç¾åœ¨åªå¾å¿«å–è®€å–ï¼Œä¸æœƒé˜»å¡ï¼ˆæ”å½±æ©Ÿåœ¨èƒŒæ™¯ç·šç¨‹è™•ç†ï¼‰
        
        Args:
            emg_channels: 8 é€šé“ EMG è³‡æ–™ï¼ˆÎ¼Vï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸæ–°å¢
        """
        if not self.recording or self.session is None:
            return False
        
        # è¨ˆç®—ç›¸å°æ™‚é–“æˆ³
        timestamp = time.time() - self.session.start_time
        
        # å¾å¿«å–è®€å–æœ€æ–°å¹€å’Œé—œéµé»ï¼ˆä¸é˜»å¡ï¼‰
        frame_image = None
        landmarks = None
        
        if self.enable_camera:
            with self._camera_lock:
                if self._cached_frame is not None:
                    frame_image = self._cached_frame.copy()
                if self._cached_landmarks is not None:
                    landmarks = self._cached_landmarks.copy()
        
        # å»ºç«‹å¹€è³‡æ–™
        motion_frame = MotionFrame(
            timestamp=timestamp,
            emg_data=np.array(emg_channels, dtype=np.float32),
            hand_landmarks=landmarks,
            frame_image=frame_image
        )
        
        self.session.frames.append(motion_frame)
        
        # è¨˜æ†¶é«”ç®¡ç†ï¼šå®šæœŸæ¸…ç†èˆŠå¹€çš„å½±åƒï¼ˆä¿ç•™æœ€æ–°çš„ MAX_FULL_IMAGE_FRAMES å¹€ï¼‰
        if len(self.session.frames) > self.MAX_FULL_IMAGE_FRAMES:
            # æ¸…ç†èˆŠå¹€çš„å½±åƒï¼Œåªä¿ç•™ landmarks å’Œ EMG
            old_frame = self.session.frames[len(self.session.frames) - self.MAX_FULL_IMAGE_FRAMES - 1]
            if old_frame.frame_image is not None:
                del old_frame.frame_image
                old_frame.frame_image = None
        
        return True
    
    def get_current_frame(self) -> tuple[Optional[np.ndarray], bool]:
        """ç²å–ç•¶å‰æ”å½±æ©Ÿå¹€ï¼ˆç”¨æ–¼é è¦½è¦–çª—ï¼‰
        
        ä½¿ç”¨å¿«å–çš„å¹€ï¼Œé¿å…é‡è¤‡è®€å–æ”å½±æ©Ÿå’Œ MediaPipe è™•ç†
        
        Returns:
            (frame, has_hand): å½±åƒå¹€å’Œæ˜¯å¦åµæ¸¬åˆ°æ‰‹éƒ¨
        """
        if not self.enable_camera or self._cached_frame is None:
            return None, False
        
        frame = self._cached_frame.copy()
        has_hand = self._cached_has_hand
        
        # å¦‚æœæœ‰åµæ¸¬åˆ°æ‰‹éƒ¨ï¼Œç¹ªè£½é—œéµé»
        if has_hand and self._cached_landmarks is not None:
            # å°‡æ­¸ä¸€åŒ–åº§æ¨™è½‰ç‚ºåƒç´ åº§æ¨™
            h, w = frame.shape[:2]
            landmarks_2d = np.array([
                [int(lm[0] * w), int(lm[1] * h)]
                for lm in self._cached_landmarks
            ])
            frame = self._draw_landmarks_on_frame(frame, landmarks_2d)
        
        return frame, has_hand
    
    def _draw_landmarks_on_frame(
        self, 
        frame: np.ndarray, 
        landmarks_2d: np.ndarray
    ) -> np.ndarray:
        """åœ¨å½±åƒä¸Šç¹ªè£½æ‰‹éƒ¨é—œéµé»ï¼ˆ2D åƒç´ åº§æ¨™ï¼‰
        
        Args:
            frame: åŸå§‹å½±åƒï¼ˆBGRï¼‰
            landmarks_2d: 21 å€‹é—œéµé»çš„ 2D åƒç´ åº§æ¨™ (21, 2)
            
        Returns:
            ç¹ªè£½å¾Œçš„å½±åƒ
        """
        # ç¹ªè£½é—œéµé»
        for point in landmarks_2d:
            cv2.circle(frame, tuple(point), 3, (0, 255, 0), -1)
        
        # ç¹ªè£½é€£ç·šï¼ˆæ‰‹æŒ‡éª¨æ¶ï¼‰
        connections = [
            # å¤§æ‹‡æŒ‡
            (0, 1), (1, 2), (2, 3), (3, 4),
            # é£ŸæŒ‡
            (0, 5), (5, 6), (6, 7), (7, 8),
            # ä¸­æŒ‡
            (0, 9), (9, 10), (10, 11), (11, 12),
            # ç„¡åæŒ‡
            (0, 13), (13, 14), (14, 15), (15, 16),
            # å°æŒ‡
            (0, 17), (17, 18), (18, 19), (19, 20),
            # æ‰‹æŒ
            (5, 9), (9, 13), (13, 17)
        ]
        
        for start_idx, end_idx in connections:
            if start_idx < len(landmarks_2d) and end_idx < len(landmarks_2d):
                start_point = tuple(landmarks_2d[start_idx])
                end_point = tuple(landmarks_2d[end_idx])
                cv2.line(frame, start_point, end_point, (255, 0, 0), 2)
        
        return frame
    
    def stop_recording(self, save_path: str) -> bool:
        """åœæ­¢è¨˜éŒ„ä¸¦å„²å­˜è³‡æ–™
        
        Args:
            save_path: å„²å­˜è·¯å¾‘ï¼ˆ.npz æ ¼å¼ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸå„²å­˜
        """
        if not self.recording or self.session is None:
            print("âš ï¸ æ²’æœ‰é€²è¡Œä¸­çš„è¨˜éŒ„")
            return False
        
        self.recording = False
        
        if len(self.session.frames) == 0:
            print("âš ï¸ æ²’æœ‰è¨˜éŒ„åˆ°ä»»ä½•è³‡æ–™")
            return False
        
        # æ›´æ–°å…ƒè³‡æ–™
        self.session.metadata['duration'] = time.time() - self.session.start_time
        self.session.metadata['num_frames'] = len(self.session.frames)
        
        # å„²å­˜è³‡è¨Šï¼ˆåœ¨é‡ç½® session å‰ï¼‰
        duration = self.session.metadata['duration']
        num_frames = self.session.metadata['num_frames']
        
        # å„²å­˜è³‡æ–™
        success = self._save_data(save_path)
        
        # å„²å­˜å½±ç‰‡ï¼ˆå¦‚æœæœ‰æ”å½±æ©Ÿè³‡æ–™ï¼‰
        if self.enable_camera and self.session.frames[0].frame_image is not None:
            video_path = save_path.replace('.npz', '.mp4')
            self._save_video(video_path)
        
        # é—œé–‰æ”å½±æ©Ÿï¼Œé‡‹æ”¾è³‡æº
        self._close_camera()
        
        # æ¸…ç†å¿«å–ï¼ˆé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼ï¼‰
        self._cached_frame = None
        self._cached_landmarks = None
        self._cached_has_hand = False
        
        # å¼·åˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # é‡ç½®æœƒè©±
        self.session = None
        
        if success:
            print(f"âœ… è³‡æ–™å·²å„²å­˜: {save_path}")
            print(f"   æ™‚é•·: {duration:.2f} ç§’")
            print(f"   å¹€æ•¸: {num_frames}")
        
        return success
    
    def _save_data(self, path: str) -> bool:
        """å„²å­˜è³‡æ–™ç‚º .npz æ ¼å¼"""
        try:
            # å»ºç«‹ç›®éŒ„
            Path(path).parent.mkdir(parents=True, exist_ok=True)
            
            # æº–å‚™è³‡æ–™
            timestamps = np.array([f.timestamp for f in self.session.frames])
            emg_data = np.array([f.emg_data for f in self.session.frames])
            
            # æ‰‹éƒ¨é—œéµé»ï¼ˆå¯èƒ½æœ‰ Noneï¼‰
            landmarks_list = []
            for f in self.session.frames:
                if f.hand_landmarks is not None:
                    landmarks_list.append(f.hand_landmarks)
                else:
                    landmarks_list.append(np.zeros((21, 3)))  # å¡«å……é›¶
            
            landmarks = np.array(landmarks_list)
            
            # æ¨™è¨˜å“ªäº›å¹€æœ‰æœ‰æ•ˆçš„æ‰‹éƒ¨åµæ¸¬
            landmarks_valid = np.array([
                f.hand_landmarks is not None 
                for f in self.session.frames
            ])
            
            # å„²å­˜
            np.savez(
                path,
                timestamps=timestamps,
                emg_data=emg_data,
                landmarks=landmarks,
                landmarks_valid=landmarks_valid,
                metadata=self.session.metadata
            )
            
            return True
            
        except Exception as e:
            print(f"âŒ å„²å­˜è³‡æ–™å¤±æ•—: {e}")
            return False
    
    def _save_video(self, path: str) -> bool:
        """å„²å­˜å½±ç‰‡"""
        try:
            if not self.session.frames or self.session.frames[0].frame_image is None:
                return False
            
            # å»ºç«‹ç›®éŒ„
            Path(path).parent.mkdir(parents=True, exist_ok=True)
            
            # å–å¾—å½±åƒå°ºå¯¸
            height, width = self.session.frames[0].frame_image.shape[:2]
            
            # å»ºç«‹å½±ç‰‡å¯«å…¥å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            fps = self.session.metadata.get('camera_fps', 30)
            out = cv2.VideoWriter(path, fourcc, fps, (width, height))
            
            # å¯«å…¥æ¯ä¸€å¹€
            for frame in self.session.frames:
                if frame.frame_image is not None:
                    # å¯é¸ï¼šåœ¨å½±åƒä¸Šç¹ªè£½æ‰‹éƒ¨é—œéµé»
                    img = frame.frame_image.copy()
                    if frame.hand_landmarks is not None:
                        img = self._draw_landmarks(img, frame.hand_landmarks)
                    out.write(img)
            
            out.release()
            print(f"âœ… å½±ç‰‡å·²å„²å­˜: {path}")
            return True
            
        except Exception as e:
            print(f"âŒ å„²å­˜å½±ç‰‡å¤±æ•—: {e}")
            return False
    
    def _draw_landmarks(
        self, 
        image: np.ndarray, 
        landmarks: np.ndarray
    ) -> np.ndarray:
        """åœ¨å½±åƒä¸Šç¹ªè£½æ‰‹éƒ¨é—œéµé»
        
        Args:
            image: åŸå§‹å½±åƒï¼ˆBGRï¼‰
            landmarks: 21 å€‹é—œéµé»åº§æ¨™ï¼ˆæ­¸ä¸€åŒ–ï¼‰
            
        Returns:
            ç¹ªè£½å¾Œçš„å½±åƒ
        """
        height, width = image.shape[:2]
        
        # ç¹ªè£½é—œéµé»
        for i, (x, y, z) in enumerate(landmarks):
            cx, cy = int(x * width), int(y * height)
            cv2.circle(image, (cx, cy), 5, (0, 255, 0), -1)
            cv2.putText(
                image, str(i), (cx + 5, cy - 5),
                cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1
            )
        
        # ç¹ªè£½é€£æ¥ç·šï¼ˆæ‰‹éƒ¨éª¨æ¶ï¼‰
        if self.mp_hands is not None:
            connections = self.mp_hands.HAND_CONNECTIONS
            for connection in connections:
                start_idx, end_idx = connection
                start = landmarks[start_idx]
                end = landmarks[end_idx]
                
                start_pt = (int(start[0] * width), int(start[1] * height))
                end_pt = (int(end[0] * width), int(end[1] * height))
                
                cv2.line(image, start_pt, end_pt, (0, 255, 0), 2)
        
        return image
    
    def get_preview_frame(self) -> Optional[np.ndarray]:
        """å–å¾—ç•¶å‰çš„æ”å½±æ©Ÿé è¦½å¹€ï¼ˆç”¨æ–¼ UI é¡¯ç¤ºï¼‰
        
        Returns:
            ç•¶å‰å¹€å½±åƒï¼ˆBGRï¼‰ï¼Œè‹¥æ”å½±æ©Ÿæœªå•Ÿç”¨å‰‡è¿”å› None
        """
        if not self.enable_camera or self.cap is None:
            return None
        
        ret, frame = self.cap.read()
        if not ret:
            return None
        
        # è™•ç†æ‰‹éƒ¨è¿½è¹¤
        if self.hands is not None:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(frame_rgb)
            
            if results.multi_hand_landmarks:
                hand = results.multi_hand_landmarks[0]
                landmarks = np.array([
                    [lm.x, lm.y, lm.z] 
                    for lm in hand.landmark
                ])
                frame = self._draw_landmarks(frame, landmarks)
        
        return frame
    
    def release(self) -> None:
        """é‡‹æ”¾è³‡æº"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        
        if self.hands is not None:
            try:
                self.hands.close()
            except (ValueError, AttributeError):
                # MediaPipe å¯èƒ½å·²ç¶“é—œé–‰
                pass
            self.hands = None
    
    def __del__(self):
        """è§£æ§‹å‡½æ•¸"""
        try:
            self.release()
        except Exception:
            pass  # å¿½ç•¥è§£æ§‹æ™‚çš„éŒ¯èª¤


def test_motion_recorder():
    """æ¸¬è©¦å‹•ä½œè¨˜éŒ„å™¨ï¼ˆç¨ç«‹æ¸¬è©¦ï¼‰"""
    print("ğŸ§ª æ¸¬è©¦ MotionRecorder...")
    print()
    
    # æª¢æŸ¥ MediaPipe å¯ç”¨æ€§
    if MEDIAPIPE_AVAILABLE:
        print("âœ… MediaPipe å·²å®‰è£ï¼Œå°‡æ¸¬è©¦å®Œæ•´åŠŸèƒ½ï¼ˆå«æ”å½±æ©Ÿï¼‰")
        enable_camera = True
    else:
        print("âš ï¸  MediaPipe æœªå®‰è£ï¼Œåƒ…æ¸¬è©¦ EMG è³‡æ–™è¨˜éŒ„")
        print("   æ³¨æ„: Python 3.13 ç›®å‰ä¸æ”¯æ´ MediaPipe")
        print("   å»ºè­°ä½¿ç”¨ Python 3.10 æˆ– 3.11 ä»¥å•Ÿç”¨å®Œæ•´åŠŸèƒ½")
        enable_camera = False
    
    print()
    
    # å»ºç«‹è¨˜éŒ„å™¨
    recorder = MotionRecorder(enable_camera=enable_camera)
    
    # é–‹å§‹è¨˜éŒ„
    recorder.start_recording("test_gesture")
    
    # æ¨¡æ“¬ EMG è³‡æ–™
    import random
    print("ğŸ“Š æ­£åœ¨è¨˜éŒ„æ¨¡æ“¬ EMG è³‡æ–™...")
    for i in range(200):  # 1 ç§’ï¼ˆ@ 200 Hzï¼‰
        emg_data = [random.uniform(-1000, 1000) for _ in range(8)]
        recorder.add_emg_sample(emg_data)
        time.sleep(0.005)  # 5ms
        
        # é¡¯ç¤ºé€²åº¦
        if (i + 1) % 50 == 0:
            print(f"   å·²è¨˜éŒ„ {i + 1}/200 å¹€")
    
    print()
    
    # åœæ­¢ä¸¦å„²å­˜
    recorder.stop_recording("recordings/test_001.npz")
    
    # é‡‹æ”¾è³‡æº
    recorder.release()
    
    print()
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print()
    
    # é©—è­‰å„²å­˜çš„è³‡æ–™
    print("ğŸ” é©—è­‰å„²å­˜çš„è³‡æ–™...")
    try:
        data = np.load("recordings/test_001.npz", allow_pickle=True)
        print(f"   âœ“ æ™‚é–“æˆ³æ•¸é‡: {len(data['timestamps'])}")
        print(f"   âœ“ EMG è³‡æ–™å½¢ç‹€: {data['emg_data'].shape}")
        print(f"   âœ“ æ‰‹éƒ¨é—œéµé»å½¢ç‹€: {data['landmarks'].shape}")
        print(f"   âœ“ æœ‰æ•ˆé—œéµé»æ•¸: {np.sum(data['landmarks_valid'])}")
        
        metadata = data['metadata'].item()
        print(f"   âœ“ æ‰‹å‹¢æ¨™ç±¤: {metadata['gesture_label']}")
        print(f"   âœ“ è¨˜éŒ„æ™‚é•·: {metadata['duration']:.2f} ç§’")
        print(f"   âœ“ æ¡æ¨£ç‡: {metadata['sample_rate']} Hz")
        
        print()
        print("âœ… è³‡æ–™é©—è­‰æˆåŠŸï¼")
        
    except Exception as e:
        print(f"   âŒ é©—è­‰å¤±æ•—: {e}")


if __name__ == "__main__":
    test_motion_recorder()
